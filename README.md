# Undergrad Senior Design
# Robustness of Microarchitecture Attacks/Malware Detection Tools against Adversarial Artificial Intelligence Attacks

The software our team will develop will assess the robustness of security systems that attempt to detect micro-architecture attacks. The robustness will be measured by its ability to detect micro-architecture attacks specially designed to evade detection. The software will generate these evasive adversary attacks by inserting artificial noise into the attack instructions to mimic benign power signatures and exploit the security systemâ€™s underlying machine-learning model.

Five micro-architecture attack codes will be provided, and all five attacks must be able to execute without detection and without significantly slowing down the attack. The security system cannot report any higher than 20% detection certainty for the attack to be undetected. The power usage should not exceed 2x normal activity, and the attack should not surpass a 5x slower data leak rate than its non-evasive counterpart.
